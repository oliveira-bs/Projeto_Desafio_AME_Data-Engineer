{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e8893ff9-7f31-4940-80d5-63e579ebac3d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/04 13:25:04 WARN Utils: Your hostname, pop-os resolves to a loopback address: 127.0.1.1; using 192.168.0.174 instead (on interface wlp7s0)\n",
      "23/09/04 13:25:04 WARN Utils: Set SPARK_LOCAL_IP if you need to bind to another address\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Setting default log level to \"WARN\".\n",
      "To adjust logging level use sc.setLogLevel(newLevel). For SparkR, use setLogLevel(newLevel).\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "23/09/04 13:25:05 WARN NativeCodeLoader: Unable to load native-hadoop library for your platform... using builtin-java classes where applicable\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import re\n",
    "\n",
    "from pyspark.sql import SparkSession\n",
    "from pyspark.sql.functions import current_timestamp\n",
    "\n",
    "spark = (SparkSession.builder\n",
    "         .master(\"local\")\n",
    "         .appName(\"ame-challenge\")\n",
    "         .getOrCreate())\n",
    "\n",
    "# set log level\n",
    "spark.sparkContext.setLogLevel(\"ERROR\")\n",
    "\n",
    "repository_path = os.getcwd()\n",
    "path_landing = repository_path + '/pipeline/landing'\n",
    "path_bronze = repository_path + '/pipeline/bronze'\n",
    "path_silver = repository_path + '/pipeline/silver'\n",
    "path_gold = repository_path + '/pipeline/gold'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "a9fe3563-d621-4199-980b-1953c011f26f",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Bronze"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "27689dc3-e073-4c2a-ae0e-545959efb1b8",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "# get file(s) in landing\n",
    "df_zipped = spark \\\n",
    "    .read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"compression\", \"gzip\") \\\n",
    "    .option(\"delimiter\", \",\") \\\n",
    "    .option(\"header\", True) \\\n",
    "    .load(f\"{path_landing}/base_de_respostas_10k_amostra_csv.gz\")\n",
    "\n",
    "# get auto schema to csv file\n",
    "df_static_sch = df_zipped.schema\n",
    "\n",
    "# configure batch for [landing]\n",
    "df_ss_bronze = spark.read \\\n",
    "    .schema(df_static_sch) \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"compression\", \"gzip\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .load(f'{path_landing}/base_de_respostas_*.gz') \\\n",
    "    .withColumn(\"loading_date_stage\", current_timestamp())\n",
    "\n",
    "# BRONZE\n",
    "# storage data in bronze zone in csv format\n",
    "df_ss_bronze.write \\\n",
    "    .mode(\"append\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_bronze}/base_de_respostas.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "5c897d4c-abdc-43f3-809c-068d9c4f5ae1",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Silver"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "58037168-6eb6-42fc-92b3-b24f6937aaf4",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "df_read_bronze = spark.read \\\n",
    "    .format(\"csv\") \\\n",
    "    .option(\"compression\", \"gzip\") \\\n",
    "    .option(\"sep\", \",\") \\\n",
    "    .option(\"header\", \"true\") \\\n",
    "    .option(\"maxFilesPerTrigger\", \"1\") \\\n",
    "    .load(f'{path_bronze}/base_de_respostas.csv') \n",
    "\n",
    "new_columns = [re.sub('([a-z0-9])([A-Z])', r'\\1_\\2', new_column).lower() for new_column in df_read_bronze.columns]\n",
    "\n",
    "df_read_bronze = df_read_bronze.toDF(*new_columns)\n",
    "\n",
    "df_transform = df_read_bronze.fillna(\n",
    "    {'company_size': 'Others', 'operating_system': 'Others', \\\n",
    "    'communication_tools': 'Others', 'language_worked_with': 'Others', \\\n",
    "    'converted_salary': 0}\n",
    "    )\n",
    "\n",
    "df_transform.createOrReplaceTempView(\"vw_transform\")\n",
    "\n",
    "df_clean_country = spark.sql(f\"\"\"\n",
    "    SELECT * \n",
    "    FROM vw_transform\n",
    "    where country IS NOT NULL\n",
    "\"\"\")\n",
    "\n",
    "df_clean_country.createOrReplaceTempView(\"vw_silver_base_respostas\")\n",
    "\n",
    "# BRONZE to SILVER\n",
    "# set typing for fields in [base_resposta]\n",
    "df_ss_silver_base_respostas = (\n",
    "    spark.sql(f\"\"\"\n",
    "        SELECT\n",
    "            CAST(respondent AS INTEGER) AS respondent,\n",
    "            CAST(concat('respondent_',respondent) AS STRING) AS nome,\n",
    "            CAST(hobby AS STRING) AS hobby,\n",
    "            CAST(hobby AS STRING) AS programa_hobby,\n",
    "            CAST(open_source AS STRING) AS open_source,\n",
    "            CAST(open_source AS STRING) AS contrib_open_source,\n",
    "            CAST(country AS STRING) AS country,\n",
    "            CAST(student AS STRING) AS student,\n",
    "            CAST(employment AS STRING) AS employment,\n",
    "            CAST(formal_education AS STRING) AS formal_education,\n",
    "            CAST(undergrad_major AS STRING) AS undergrad_major,\n",
    "            CAST(company_size AS STRING) AS company_size,\n",
    "            CAST(dev_type AS STRING) AS dev_type,\n",
    "            CAST(years_coding AS STRING) AS years_coding,\n",
    "            CAST(years_coding_prof AS STRING) AS years_coding_prof,\n",
    "            CAST(job_satisfaction AS STRING) AS job_satisfaction,\n",
    "            CAST(career_satisfaction AS STRING) AS career_satisfaction,\n",
    "            CAST(hope_five_years AS STRING) AS hope_five_years,\n",
    "            CAST(job_search_status AS STRING) AS job_search_status,\n",
    "            CAST(last_new_job AS STRING) AS last_new_job,\n",
    "            CAST(assess_job1 AS DOUBLE) AS assess_job1,\n",
    "            CAST(assess_job2 AS DOUBLE) AS assess_job2,\n",
    "            CAST(assess_job3 AS DOUBLE) AS assess_job3,\n",
    "            CAST(assess_job4 AS DOUBLE) AS assess_job4,\n",
    "            CAST(assess_job5 AS DOUBLE) AS assess_job5,\n",
    "            CAST(assess_job6 AS DOUBLE) AS assess_job6,\n",
    "            CAST(assess_job7 AS DOUBLE) AS assess_job7,\n",
    "            CAST(assess_job8 AS DOUBLE) AS assess_job8,\n",
    "            CAST(assess_job9 AS DOUBLE) AS assess_job9,\n",
    "            CAST(assess_job10 AS DOUBLE) AS assess_job10,\n",
    "            CAST(assess_benefits1 AS DOUBLE) AS assess_benefits1,\n",
    "            CAST(assess_benefits2 AS DOUBLE) AS assess_benefits2,\n",
    "            CAST(assess_benefits3 AS DOUBLE) AS assess_benefits3,\n",
    "            CAST(assess_benefits4 AS DOUBLE) AS assess_benefits4,\n",
    "            CAST(assess_benefits5 AS DOUBLE) AS assess_benefits5,\n",
    "            CAST(assess_benefits6 AS DOUBLE) AS assess_benefits6,\n",
    "            CAST(assess_benefits7 AS DOUBLE) AS assess_benefits7,\n",
    "            CAST(assess_benefits8 AS DOUBLE) AS assess_benefits8,\n",
    "            CAST(assess_benefits9 AS DOUBLE) AS assess_benefits9,\n",
    "            CAST(assess_benefits10 AS DOUBLE) AS assess_benefits10,\n",
    "            CAST(assess_benefits11 AS DOUBLE) AS assess_benefits11,\n",
    "            CAST(job_contact_priorities1 AS DOUBLE) AS job_contact_priorities1,\n",
    "            CAST(job_contact_priorities2 AS DOUBLE) AS job_contact_priorities2,\n",
    "            CAST(job_contact_priorities3 AS DOUBLE) AS job_contact_priorities3,\n",
    "            CAST(job_contact_priorities4 AS DOUBLE) AS job_contact_priorities4,\n",
    "            CAST(job_contact_priorities5 AS DOUBLE) AS job_contact_priorities5,\n",
    "            CAST(job_email_priorities1 AS DOUBLE) AS job_email_priorities1,\n",
    "            CAST(job_email_priorities2 AS DOUBLE) AS job_email_priorities2,\n",
    "            CAST(job_email_priorities3 AS DOUBLE) AS job_email_priorities3,\n",
    "            CAST(job_email_priorities4 AS DOUBLE) AS job_email_priorities4,\n",
    "            CAST(job_email_priorities5 AS DOUBLE) AS job_email_priorities5,\n",
    "            CAST(job_email_priorities6 AS DOUBLE) AS job_email_priorities6,\n",
    "            CAST(job_email_priorities7 AS DOUBLE) AS job_email_priorities7,\n",
    "            CAST(update_cv AS STRING) AS update_cv,\n",
    "            CAST(currency AS STRING) AS currency,\n",
    "            CAST(salary AS INTEGER) AS salary,\n",
    "            CAST(salary_type AS STRING) AS salary_type,\n",
    "            CAST(converted_salary AS DOUBLE) AS converted_salary,\n",
    "            CAST(round(converted_salary*3.81, 2) AS DOUBLE) as salario_anual,\n",
    "            CAST(round(converted_salary*3.81/12, 2) AS DOUBLE) as salario,\n",
    "            CAST(currency_symbol AS STRING) AS currency_symbol,\n",
    "            CAST(communication_tools AS STRING) AS communication_tools,\n",
    "            CAST(time_fully_productive AS STRING) AS time_fully_productive,\n",
    "            CAST(education_types AS STRING) AS education_types,\n",
    "            CAST(self_taught_types AS STRING) AS self_taught_types,\n",
    "            CAST(time_after_bootcamp AS STRING) AS time_after_bootcamp,\n",
    "            CAST(hackathon_reasons AS STRING) AS hackathon_reasons,\n",
    "            CAST(agree_disagree1 AS STRING) AS agree_disagree1,\n",
    "            CAST(agree_disagree2 AS STRING) AS agree_disagree2,\n",
    "            CAST(agree_disagree3 AS STRING) AS agree_disagree3,\n",
    "            CAST(language_worked_with AS STRING) AS language_worked_with,\n",
    "            CAST(language_desire_next_year AS STRING) AS language_desire_next_year,\n",
    "            CAST(database_worked_with AS STRING) AS database_worked_with,\n",
    "            CAST(database_desire_next_year AS STRING) AS database_desire_next_year,\n",
    "            CAST(platform_worked_with AS STRING) AS platform_worked_with,\n",
    "            CAST(platform_desire_next_year AS STRING) AS platform_desire_next_year,\n",
    "            CAST(framework_worked_with AS STRING) AS framework_worked_with,\n",
    "            CAST(framework_desire_next_year AS STRING) AS framework_desire_next_year,\n",
    "            CAST(ide AS STRING) AS ide,\n",
    "            CAST(operating_system AS STRING) AS operating_system,\n",
    "            CAST(number_monitors AS INTEGER) AS number_monitors,\n",
    "            CAST(methodology AS STRING) AS methodology,\n",
    "            CAST(version_control AS STRING) AS version_control,\n",
    "            CAST(check_in_code AS STRING) AS check_in_code,\n",
    "            CAST(ad_blocker AS STRING) AS ad_blocker,\n",
    "            CAST(ad_blocker_disable AS STRING) AS ad_blocker_disable,\n",
    "            CAST(ad_blocker_reasons AS STRING) AS ad_blocker_reasons,\n",
    "            CAST(ads_agree_disagree1 AS STRING) AS ads_agree_disagree1,\n",
    "            CAST(ads_agree_disagree2 AS STRING) AS ads_agree_disagree2,\n",
    "            CAST(ads_agree_disagree3 AS STRING) AS ads_agree_disagree3,\n",
    "            CAST(ads_actions AS STRING) AS ads_actions,\n",
    "            CAST(ads_priorities1 AS DOUBLE) AS ads_priorities1,\n",
    "            CAST(ads_priorities2 AS DOUBLE) AS ads_priorities2,\n",
    "            CAST(ads_priorities3 AS DOUBLE) AS ads_priorities3,\n",
    "            CAST(ads_priorities4 AS DOUBLE) AS ads_priorities4,\n",
    "            CAST(ads_priorities5 AS DOUBLE) AS ads_priorities5,\n",
    "            CAST(ads_priorities6 AS DOUBLE) AS ads_priorities6,\n",
    "            CAST(ads_priorities7 AS DOUBLE) AS ads_priorities7,\n",
    "            CAST(aidangerous AS STRING) AS aidangerous,\n",
    "            CAST(aiinteresting AS STRING) AS aiinteresting,\n",
    "            CAST(airesponsible AS STRING) AS airesponsible,\n",
    "            CAST(aifuture AS STRING) AS aifuture,\n",
    "            CAST(ethics_choice AS STRING) AS ethics_choice,\n",
    "            CAST(ethics_report AS STRING) AS ethics_report,\n",
    "            CAST(ethics_responsible AS STRING) AS ethics_responsible,\n",
    "            CAST(ethical_implications AS STRING) AS ethical_implications,\n",
    "            CAST(stack_overflow_recommend AS INTEGER) AS stack_overflow_recommend,\n",
    "            CAST(stack_overflow_visit AS STRING) AS stack_overflow_visit,\n",
    "            CAST(stack_overflow_has_account AS STRING) AS stack_overflow_has_account,\n",
    "            CAST(stack_overflow_participate AS STRING) AS stack_overflow_participate,\n",
    "            CAST(stack_overflow_jobs AS STRING) AS stack_overflow_jobs,\n",
    "            CAST(stack_overflow_dev_story AS STRING) AS stack_overflow_dev_story,\n",
    "            CAST(stack_overflow_jobs_recommend AS INTEGER) AS stack_overflow_jobs_recommend,\n",
    "            CAST(stack_overflow_consider_member AS STRING) AS stack_overflow_consider_member,\n",
    "            CAST(hypothetical_tools1 AS STRING) AS hypothetical_tools1,\n",
    "            CAST(hypothetical_tools2 AS STRING) AS hypothetical_tools2,\n",
    "            CAST(hypothetical_tools3 AS STRING) AS hypothetical_tools3,\n",
    "            CAST(hypothetical_tools4 AS STRING) AS hypothetical_tools4,\n",
    "            CAST(hypothetical_tools5 AS STRING) AS hypothetical_tools5,\n",
    "            CAST(wake_time AS STRING) AS wake_time,\n",
    "            CAST(hours_computer AS STRING) AS hours_computer,\n",
    "            CAST(hours_outside AS STRING) AS hours_outside,\n",
    "            CAST(skip_meals AS STRING) AS skip_meals,\n",
    "            CAST(ergonomic_devices AS STRING) AS ergonomic_devices,\n",
    "            CAST(exercise AS STRING) AS exercise,\n",
    "            CAST(gender AS STRING) AS gender,\n",
    "            CAST(sexual_orientation AS STRING) AS sexual_orientation,\n",
    "            CAST(education_parents AS STRING) AS education_parents,\n",
    "            CAST(race_ethnicity AS STRING) AS race_ethnicity,\n",
    "            CAST(age AS STRING) AS age,\n",
    "            CAST(dependents AS STRING) AS dependents,\n",
    "            CAST(military_us AS STRING) AS military_us,\n",
    "            CAST(survey_too_long AS STRING) AS survey_too_long,\n",
    "            CAST(survey_easy AS STRING) AS survey_easy,\n",
    "            CAST(loading_date_stage AS TIMESTAMP) AS loading_date_stage\n",
    "        FROM\n",
    "            (\n",
    "            SELECT DENSE_RANK() OVER(ORDER BY loading_date_stage DESC) AS rank, *\n",
    "            FROM vw_silver_base_respostas\n",
    "            ) AS T\n",
    "        WHERE\n",
    "            T.rank = 1\n",
    "            \"\"\")\n",
    ")\n",
    "# storage data in silver zone in csv format\n",
    "(\n",
    "    df_ss_silver_base_respostas\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_silver}/base_de_respostas.csv\")\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "e7044f7b-957a-488f-bd21-7a642fc6435e",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Gold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "7115c27b-6a97-4545-ae49-323024f2198d",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>nome</th>\n",
       "      <th>contrib_open_source</th>\n",
       "      <th>programa_hobby</th>\n",
       "      <th>salario</th>\n",
       "      <th>sistema_operacional_id</th>\n",
       "      <th>pais_id</th>\n",
       "      <th>empresa_id</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>101346</td>\n",
       "      <td>respondent_101346</td>\n",
       "      <td>No</td>\n",
       "      <td>No</td>\n",
       "      <td>15875.0</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44791</td>\n",
       "      <td>respondent_44791</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>25257.76</td>\n",
       "      <td>4</td>\n",
       "      <td>42</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>32306</td>\n",
       "      <td>respondent_32306</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>39687.5</td>\n",
       "      <td>4</td>\n",
       "      <td>130</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>37142</td>\n",
       "      <td>respondent_37142</td>\n",
       "      <td>No</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>2</td>\n",
       "      <td>130</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>21745</td>\n",
       "      <td>respondent_21745</td>\n",
       "      <td>Yes</td>\n",
       "      <td>Yes</td>\n",
       "      <td>0.0</td>\n",
       "      <td>4</td>\n",
       "      <td>81</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       id               nome contrib_open_source programa_hobby   salario  \\\n",
       "0  101346  respondent_101346                  No             No   15875.0   \n",
       "1   44791   respondent_44791                  No            Yes  25257.76   \n",
       "2   32306   respondent_32306                 Yes            Yes   39687.5   \n",
       "3   37142   respondent_37142                  No            Yes       0.0   \n",
       "4   21745   respondent_21745                 Yes            Yes       0.0   \n",
       "\n",
       "   sistema_operacional_id  pais_id  empresa_id  \n",
       "0                       4      130           3  \n",
       "1                       4       42           0  \n",
       "2                       4      130           2  \n",
       "3                       2      130           1  \n",
       "4                       4       81           4  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_read_silver = (\n",
    "    spark.read.format(\"csv\")\n",
    "    .option(\"sep\", \",\")\n",
    "    .option(\"header\", \"true\")\n",
    "    .option(\"maxFilesPerTrigger\", \"1\")\n",
    "    .load(f\"{path_silver}/base_de_respostas.csv\")\n",
    ")\n",
    "\n",
    "df_read_silver.createOrReplaceTempView(\"vw_base_silver\")\n",
    "\n",
    "# write dataframe [empresa] in gold zone\n",
    "df_empresa = spark.sql(\"\"\"\n",
    "    select ROW_NUMBER() OVER (ORDER BY (SELECT 1)) - 1 as id, company_size AS tamanho\n",
    "    from \n",
    "    (\n",
    "        select distinct company_size\n",
    "        from vw_base_silver\n",
    "        order by company_size asc\n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_empresa\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/empresa.csv\")\n",
    ")\n",
    "\n",
    "df_empresa.createOrReplaceTempView('vw_empresa')\n",
    "\n",
    "# write dataframe [pais] in gold zone\n",
    "df_pais = spark.sql(\"\"\"\n",
    "    select ROW_NUMBER() OVER (ORDER BY (SELECT 1)) - 1 as id, country AS nome\n",
    "    from \n",
    "    (\n",
    "        select distinct country\n",
    "        from vw_base_silver\n",
    "        order by country asc    \n",
    "    )\n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_pais\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/pais.csv\")\n",
    ")\n",
    "\n",
    "df_pais.createOrReplaceTempView('vw_pais')\n",
    "\n",
    "# write dataframe [sistema_operacional] in gold zone\n",
    "df_sistema_operacional = spark.sql(\n",
    "    \"\"\"\n",
    "    select ROW_NUMBER() OVER (ORDER BY (SELECT 1)) - 1 as id, operating_system AS nome\n",
    "    from \n",
    "    (\n",
    "        select distinct operating_system\n",
    "        from vw_base_silver\n",
    "        order by operating_system asc\n",
    "    );                                   \n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_sistema_operacional\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/sistema_operacional.csv\")\n",
    ")\n",
    "\n",
    "df_sistema_operacional.createOrReplaceTempView('vw_sistema_operacional')\n",
    "\n",
    "# write dataframe [ferramenta_comunic] in gold zone\n",
    "df_ferramenta_comunic = spark.sql(\"\"\"\n",
    "    select ROW_NUMBER() OVER (ORDER BY (SELECT 1)) - 1 as id, nome\n",
    "    from \n",
    "    (\n",
    "        SELECT DISTINCT trim(split_communication_tools) as nome\n",
    "        FROM vw_base_silver\n",
    "        LATERAL VIEW explode(split(communication_tools, ';')) AS split_communication_tools\n",
    "    );                                   \n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_ferramenta_comunic\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/ferramenta_comunic.csv\")\n",
    ")\n",
    "\n",
    "df_ferramenta_comunic.createOrReplaceTempView(\"vw_ferramenta_comunic\")\n",
    "\n",
    "# write dataframe [linguagem_programacao] in gold zone\n",
    "df_linguagem_programacao = spark.sql(\"\"\"\n",
    "    select ROW_NUMBER() OVER (ORDER BY (SELECT 1)) - 1 as id, nome\n",
    "    from \n",
    "    (\n",
    "        SELECT DISTINCT trim(split_language_worked_with) as nome\n",
    "        FROM vw_base_silver\n",
    "        LATERAL VIEW explode(split(language_worked_with, ';')) AS split_language_worked_with\n",
    "    );                                   \n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_linguagem_programacao\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/linguagem_programacao.csv\")\n",
    ")\n",
    "\n",
    "df_linguagem_programacao.createOrReplaceTempView(\"vw_linguagem_programacao\")\n",
    "\n",
    "# write dataframe [resp_usa_ferramenta] in gold zone\n",
    "df_resp_usa_ferramenta = spark.sql(\"\"\"\n",
    "    with respondent_communication_tools as \n",
    "    (\n",
    "        select respondent, split_communication_tools\n",
    "        from \n",
    "        (\n",
    "            SELECT *\n",
    "            FROM vw_base_silver\n",
    "            LATERAL VIEW explode(split(communication_tools, ';')) AS split_communication_tools\n",
    "        )\n",
    "    )\n",
    "    select id as ferramenta_comunic_id, respondent as respondent_id\n",
    "    from vw_ferramenta_comunic as vfc\n",
    "    inner join respondent_communication_tools as rct\n",
    "    on vfc.nome = rct.split_communication_tools;     \n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_resp_usa_ferramenta\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/resp_usa_ferramenta.csv\")\n",
    ")\n",
    "\n",
    "# write dataframe [resp_usa_linguagem] in gold zone\n",
    "df_resp_usa_linguagem = spark.sql(\"\"\"\n",
    "    with respondent_language AS \n",
    "    (\n",
    "        select respondent, split_language_worked_with, years_coding\n",
    "        from vw_base_silver\n",
    "        LATERAL VIEW explode(split(language_worked_with, ';')) AS split_language_worked_with\n",
    "    )\n",
    "    select respondent as respondent_id, id as language_worked_with_id, years_coding as momento\n",
    "    from respondent_language as rlg\n",
    "    inner join vw_linguagem_programacao as vlp\n",
    "    on rlg.split_language_worked_with = vlp.nome\n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_resp_usa_linguagem\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/resp_usa_linguagem.csv\")\n",
    ")\n",
    "\n",
    "# write dataframe [respondent] in gold zone\n",
    "df_respondente = spark.sql(\"\"\"\n",
    "    with tabela_fato as\n",
    "    (\n",
    "        select\n",
    "        respondent as id, nome,\n",
    "        contrib_open_source, programa_hobby, salario, \n",
    "        operating_system, country, company_size \n",
    "        from vw_base_silver\n",
    "    )\n",
    "    select \n",
    "        tbf.`id`, tbf.nome, contrib_open_source, programa_hobby, \n",
    "        salario, vso.`id` as sistema_operacional_id, \n",
    "        vpa.`id` as pais_id, vem.`id` as empresa_id\n",
    "    from tabela_fato as tbf\n",
    "    inner join vw_empresa vem\n",
    "    on tbf.company_size = vem.tamanho\n",
    "    inner join vw_pais as vpa\n",
    "    on tbf.country = vpa.nome\n",
    "    inner join vw_sistema_operacional as vso\n",
    "    on vso.nome = tbf.operating_system\n",
    "\"\"\")\n",
    "\n",
    "(\n",
    "    df_respondente\n",
    "    .write \\\n",
    "    .mode(\"overwrite\") \\\n",
    "    .option('header', 'true') \\\n",
    "    .csv(f\"{path_gold}/respondente.csv\")\n",
    ")\n",
    "\n",
    "df_respondente.createOrReplaceTempView('vw_respondente')\n",
    "\n",
    "df_respondente.toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "2fba7448-26a1-474f-a682-c5d2fba9949c",
     "showTitle": false,
     "title": ""
    }
   },
   "source": [
    "#### Data Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "application/vnd.databricks.v1+cell": {
     "cellMetadata": {
      "byteLimit": 2048000,
      "rowLimit": 10000
     },
     "inputWidgets": {},
     "nuid": "36d5d142-797c-4858-b9d6-048ad554919a",
     "showTitle": false,
     "title": ""
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DataFrame[]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# create database [ame_digital]\n",
    "spark.sql(\"DROP DATABASE IF EXISTS ame_digital CASCADE\")\n",
    "spark.sql(\"CREATE DATABASE IF NOT EXISTS ame_digital\")\n",
    "spark.sql(\"USE ame_digital\")\n",
    "\n",
    "# create table [empresa]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists empresa;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists empresa\n",
    "    (\n",
    "        `id`            integer,\n",
    "        tamanho         string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/empresa.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [pais]\n",
    "spark.sql(f\"\"\"\n",
    "    drop table if exists pais;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists pais\n",
    "    (\n",
    "        `id`            integer,\n",
    "        nome            string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/pais.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [sistema_operacional]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists sistema_operacional;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists sistema_operacional\n",
    "    (\n",
    "        `id`            integer,\n",
    "        nome            string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/sistema_operacional.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [ferramenta_comunic]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists ferramenta_comunic;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists ferramenta_comunic\n",
    "    (\n",
    "        `id`            integer,\n",
    "        nome            string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/ferramenta_comunic.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [linguagem_programacao]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists linguagem_programacao;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists linguagem_programacao\n",
    "    (\n",
    "        `id`            integer,\n",
    "        nome            string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/linguagem_programacao.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [resp_usa_ferramenta]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists resp_usa_ferramenta;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists resp_usa_ferramenta\n",
    "    (\n",
    "        ferramenta_comunic_id   integer,\n",
    "        respondente_id          integer\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/resp_usa_ferramenta.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [resp_usa_linguagem]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists resp_usa_linguagem;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists resp_usa_linguagem\n",
    "    (\n",
    "        respondente_id              integer,\n",
    "        linguagem_programacao_id    integer,\n",
    "        momento                     string\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/resp_usa_linguagem.csv\"\n",
    "    );       \n",
    "\"\"\")\n",
    "\n",
    "# create table [respondente]\n",
    "spark.sql(\"\"\"\n",
    "    drop table if exists respondente;\n",
    "\"\"\")\n",
    "spark.sql(f\"\"\"\n",
    "    create table if not exists respondente\n",
    "    (\n",
    "        `id`                    integer,\n",
    "        nome                    string,\n",
    "        contrib_open_source     string,\n",
    "        programa_hobby          string,\n",
    "        salario                 double,\n",
    "        sistema_operacional_id  integer,\n",
    "        pais_id                 integer,\n",
    "        empresa_id              integer\n",
    "    )\n",
    "    USING CSV\n",
    "    OPTIONS(\n",
    "        header=\"true\",\n",
    "        delimiter=\",\",\n",
    "        inferSchema=\"true\",\n",
    "        path=\"{path_gold}/respondente.csv\"\n",
    "    );       \n",
    "\"\"\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Análise dos dados - Data Warehouse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. Qual a quantidade de respondentes de cada país?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>nome</th>\n",
       "      <th>qtd_total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>2350</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>1124</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>749</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Germany</td>\n",
       "      <td>655</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>360</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             nome  qtd_total\n",
       "0   United States       2350\n",
       "1           India       1124\n",
       "2  United Kingdom        749\n",
       "3         Germany        655\n",
       "4          Canada        360"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    select pais.nome, count(*) as qtd_total\n",
    "    from respondente as rpdt\n",
    "    inner join pais \n",
    "    on rpdt.pais_id = pais.`id`\n",
    "    group by pais.nome\n",
    "    order by qtd_total desc;           \n",
    "\"\"\").toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Quantos usuários que moram em \"United States\" gostam de Windows?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sistema_operacional</th>\n",
       "      <th>total_qtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Windows</td>\n",
       "      <td>961</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sistema_operacional  total_qtd\n",
       "0             Windows        961"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with os_pais_usa as \n",
    "    (\n",
    "        select pais.nome as pais, os.nome as sistema_operacional\n",
    "        from respondente as rpdt\n",
    "        inner join pais \n",
    "        on rpdt.pais_id = pais.`id`\n",
    "        inner join sistema_operacional as os\n",
    "        on rpdt.sistema_operacional_id = os.`id`\n",
    "        where pais.nome == \"United States\"\n",
    "    )\n",
    "    select sistema_operacional, count(*) as total_qtd\n",
    "    from os_pais_usa\n",
    "    where sistema_operacional = \"Windows\"\n",
    "    group by sistema_operacional\n",
    "    order by total_qtd desc\n",
    "\"\"\").toPandas().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "3. Qual a média de salário dos usuários que moram em Israel e gostam de Linux?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pais</th>\n",
       "      <th>sistema_operacional</th>\n",
       "      <th>salario_medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Israel</td>\n",
       "      <td>Linux-based</td>\n",
       "      <td>19278.15</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     pais sistema_operacional  salario_medio\n",
       "0  Israel         Linux-based       19278.15"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "  with israel_salario_linux as \n",
    "  (\n",
    "    select pais.nome as pais, os.nome as sistema_operacional, round(rpdt.salario, 2) as salario\n",
    "    from respondente as rpdt\n",
    "    inner join pais \n",
    "    on rpdt.pais_id = pais.`id`\n",
    "    inner join sistema_operacional as os\n",
    "    on rpdt.sistema_operacional_id = os.`id`\n",
    "    where pais.nome == \"Israel\" and os.nome like \"%Linux%\"\n",
    "  )\n",
    "  select pais, sistema_operacional,\n",
    "  round(avg(salario) over(), 2) as salario_medio\n",
    "  from israel_salario_linux\n",
    "  limit 1;\n",
    "\"\"\").toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "4. Qual a média e o desvio padrão do salário dos usuários que usam Slack para cada tamanho de empresa disponível?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tamanho</th>\n",
       "      <th>media_salario</th>\n",
       "      <th>desvio_p_salario</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Fewer than 10 employees</td>\n",
       "      <td>20136.98</td>\n",
       "      <td>31788.78</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>100 to 499 employees</td>\n",
       "      <td>32889.28</td>\n",
       "      <td>56389.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5,000 to 9,999 employees</td>\n",
       "      <td>55232.78</td>\n",
       "      <td>135550.09</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1,000 to 4,999 employees</td>\n",
       "      <td>37202.95</td>\n",
       "      <td>64732.08</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>20 to 99 employees</td>\n",
       "      <td>32882.74</td>\n",
       "      <td>65515.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>500 to 999 employees</td>\n",
       "      <td>19301.02</td>\n",
       "      <td>16146.19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>10,000 or more employees</td>\n",
       "      <td>29963.25</td>\n",
       "      <td>58739.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Others</td>\n",
       "      <td>30810.29</td>\n",
       "      <td>53100.91</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>10 to 19 employees</td>\n",
       "      <td>22170.60</td>\n",
       "      <td>46713.61</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                    tamanho  media_salario  desvio_p_salario\n",
       "0   Fewer than 10 employees       20136.98          31788.78\n",
       "1      100 to 499 employees       32889.28          56389.19\n",
       "2  5,000 to 9,999 employees       55232.78         135550.09\n",
       "3  1,000 to 4,999 employees       37202.95          64732.08\n",
       "4        20 to 99 employees       32882.74          65515.58\n",
       "5      500 to 999 employees       19301.02          16146.19\n",
       "6  10,000 or more employees       29963.25          58739.59\n",
       "7                    Others       30810.29          53100.91\n",
       "8        10 to 19 employees       22170.60          46713.61"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "user_slack_company = spark.sql(\"\"\"\n",
    "with salario_empresa_slack as\n",
    "(\n",
    "  with empresa_ferramenta_id as\n",
    "  (\n",
    "    with salario_empresa as\n",
    "    (\n",
    "      select rpdt.`id`, rpdt.salario, emp.tamanho \n",
    "      from respondente as rpdt\n",
    "      inner join empresa as emp \n",
    "      on rpdt.empresa_id = emp.`id`\n",
    "      where rpdt.programa_hobby like 'No'\n",
    "    )\n",
    "    select `id`, salario, tamanho, ferramenta_comunic_id\n",
    "    from salario_empresa as semp\n",
    "    inner join resp_usa_ferramenta as ruf\n",
    "    on semp.`id` = ruf.respondente_id\n",
    "  )\n",
    "  select efi.`id`, efi.salario, efi.tamanho, fco.nome\n",
    "  from empresa_ferramenta_id as efi\n",
    "  inner join ferramenta_comunic fco\n",
    "  on efi.ferramenta_comunic_id = fco.`id`\n",
    "  where fco.nome == \"Slack\"\n",
    ")\n",
    "select tamanho, round(avg(salario), 2) as media_salario, round(stddev(salario), 2) as desvio_p_salario\n",
    "from salario_empresa_slack as ses\n",
    "group by tamanho;\n",
    "\"\"\")\n",
    "user_slack_company.toPandas().head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "5. Qual a diferença entre a média de salário dos respondentes do Brasil que acham que criar código é um hobby e a média de todos de salário de todos os respondentes brasileiros agrupado por cada sistema operacional que eles usam?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sistema_operacional</th>\n",
       "      <th>media_geral</th>\n",
       "      <th>media_hobby</th>\n",
       "      <th>diff_media</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>BSD/Unix</td>\n",
       "      <td>264490.20</td>\n",
       "      <td>264490.20</td>\n",
       "      <td>0.00</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Linux-based</td>\n",
       "      <td>10639.82</td>\n",
       "      <td>12079.34</td>\n",
       "      <td>1439.52</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>MacOS</td>\n",
       "      <td>8596.77</td>\n",
       "      <td>9320.15</td>\n",
       "      <td>723.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Others</td>\n",
       "      <td>2779.93</td>\n",
       "      <td>3188.75</td>\n",
       "      <td>408.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Windows</td>\n",
       "      <td>9366.60</td>\n",
       "      <td>10828.90</td>\n",
       "      <td>1462.30</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  sistema_operacional  media_geral  media_hobby  diff_media\n",
       "0            BSD/Unix    264490.20    264490.20        0.00\n",
       "1         Linux-based     10639.82     12079.34     1439.52\n",
       "2               MacOS      8596.77      9320.15      723.38\n",
       "3              Others      2779.93      3188.75      408.82\n",
       "4             Windows      9366.60     10828.90     1462.30"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with media_geral_os as\n",
    "    (\n",
    "      select os.nome as sistema_operacional, round(avg(rpdt.salario), 2) as media_geral\n",
    "      from respondente as rpdt\n",
    "      inner join pais as pa\n",
    "      on rpdt.pais_id = pa.`id`\n",
    "      inner join sistema_operacional as os\n",
    "      on rpdt.sistema_operacional_id = os.`id`\n",
    "      where pa.nome == \"Brazil\"\n",
    "      group by sistema_operacional\n",
    "    ),\n",
    "    media_hobby_os as \n",
    "    (\n",
    "      select os.nome as sistema_operacional, round(avg(rpdt.salario), 2) as media_hobby\n",
    "      from respondente as rpdt\n",
    "      inner join pais as pa\n",
    "      on rpdt.pais_id = pa.`id`\n",
    "      inner join sistema_operacional as os\n",
    "      on rpdt.sistema_operacional_id = os.`id`\n",
    "      where pa.nome == \"Brazil\"\n",
    "        and rpdt.programa_hobby == 'Yes'\n",
    "      group by sistema_operacional\n",
    "    )\n",
    "    select mgo.sistema_operacional, mgo.media_geral, mho.media_hobby,\n",
    "    round(abs(mgo.media_geral - mho.media_hobby), 2) as diff_media\n",
    "    from media_geral_os as mgo\n",
    "    inner join media_hobby_os as mho\n",
    "    on mgo.sistema_operacional = mho.sistema_operacional\n",
    "    order by mgo.sistema_operacional asc;\n",
    "\"\"\").toPandas().head(10)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "6. Quais são as top 3 tecnologias mais usadas pelos desenvolvedores?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>tecnologia</th>\n",
       "      <th>total_qtd</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>JavaScript</td>\n",
       "      <td>6286</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HTML</td>\n",
       "      <td>6081</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>CSS</td>\n",
       "      <td>5810</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   tecnologia  total_qtd\n",
       "0  JavaScript       6286\n",
       "1        HTML       6081\n",
       "2         CSS       5810"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with tecnologias_respondente as\n",
    "    (\n",
    "      with respondente_linguagem as \n",
    "      (\n",
    "        select *\n",
    "        from respondente as rpdt\n",
    "        inner join resp_usa_linguagem as rul\n",
    "        on rpdt.`id` = rul.respondente_id\n",
    "      )\n",
    "      select rl.`id`, lp.nome\n",
    "      from respondente_linguagem as rl\n",
    "      inner join linguagem_programacao as lp\n",
    "      on rl.linguagem_programacao_id = lp.`id`\n",
    "    )\n",
    "    select nome as tecnologia, count(*) as total_qtd\n",
    "    from tecnologias_respondente\n",
    "    group by nome\n",
    "    order by total_qtd desc\n",
    "    limit 3;\n",
    "\"\"\").toPandas().head()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "7. Quais são os top 5 países em questão de salário?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pais</th>\n",
       "      <th>salario_medio</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ireland</td>\n",
       "      <td>95661.33</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>New Zealand</td>\n",
       "      <td>46951.73</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Australia</td>\n",
       "      <td>38826.03</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>United States</td>\n",
       "      <td>37461.70</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Canada</td>\n",
       "      <td>29266.62</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            pais  salario_medio\n",
       "0        Ireland       95661.33\n",
       "1    New Zealand       46951.73\n",
       "2      Australia       38826.03\n",
       "3  United States       37461.70\n",
       "4         Canada       29266.62"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with salario_pais as\n",
    "    (\n",
    "      select pa.nome, rpdt.salario\n",
    "      from respondente as rpdt\n",
    "      inner join pais as pa\n",
    "      on rpdt.pais_id = pa.`id`\n",
    "      where rpdt.programa_hobby = 'No'\n",
    "    ), \n",
    "    media_salario as\n",
    "    (\n",
    "        select nome as pais, round(avg(salario), 2) as salario_medio, count(salario) as qtd_empregados\n",
    "        from salario_pais\n",
    "        group by pais\n",
    "        order by salario_medio desc\n",
    "    )\n",
    "    select pais, salario_medio\n",
    "    from media_salario\n",
    "    where qtd_empregados > 10\n",
    "    order by salario_medio desc\n",
    "    limit 5;\n",
    "\"\"\").toPandas().head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "8. A tabela abaixo contém os salários mínimos mensais de cinco países presentes na amostra de dados. Baseado nesses valores, gostaríamos de saber quantos usuários ganham mais de 5 salários mínimos em cada um desses países."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![fig](imagens/Picture6.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[Stage 205:>                                                        (0 + 1) / 1]\r"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "+--------------+--------------+\n",
      "|     nome_pais|salario_minimo|\n",
      "+--------------+--------------+\n",
      "| United States|        4787.9|\n",
      "|         India|        243.52|\n",
      "|United Kingdom|       6925.63|\n",
      "|       Germany|        6664.0|\n",
      "|        Canada|       5567.68|\n",
      "+--------------+--------------+\n",
      "\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "                                                                                \r"
     ]
    }
   ],
   "source": [
    "datas_salarios_minimos = [\n",
    "    ('United States', 4787.90), ('India', 243.52), \\\n",
    "    ('United Kingdom', 6925.63), ('Germany', 6664.00), \\\n",
    "    ('Canada', 5567.68)\n",
    "    ]\n",
    "columns_salario = ['nome_pais', 'salario_minimo']\n",
    "salarios_minimos = spark.createDataFrame(datas_salarios_minimos).toDF(*columns_salario)\n",
    "salarios_minimos.createOrReplaceTempView('vw_salario_minimo')\n",
    "salarios_minimos.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>pais</th>\n",
       "      <th>total</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>United States</td>\n",
       "      <td>1385</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>India</td>\n",
       "      <td>496</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>United Kingdom</td>\n",
       "      <td>128</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Canada</td>\n",
       "      <td>60</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Germany</td>\n",
       "      <td>52</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             pais  total\n",
       "0   United States   1385\n",
       "1           India    496\n",
       "2  United Kingdom    128\n",
       "3          Canada     60\n",
       "4         Germany     52"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spark.sql(\"\"\"\n",
    "    with maior_cinco_salarios_minimos as \n",
    "    (\n",
    "        with selecao_paises_salario as \n",
    "        (\n",
    "        select rpdt.`id`, pa.nome as pais, salario\n",
    "        from respondente as rpdt\n",
    "        inner join pais as pa\n",
    "        on rpdt.pais_id = pa.`id`\n",
    "        where pa.nome = \"United States\"\n",
    "            or pa.nome = \"United Kingdom\"\n",
    "            or pa.nome =\"India\" \n",
    "            or pa.nome =\"Germany\" \n",
    "            or pa.nome =\"Canada\"\n",
    "        )\n",
    "        select *,\n",
    "        5*salario_minimo as cinco_salarios_minimos\n",
    "        from vw_salario_minimo as vsm\n",
    "        inner join selecao_paises_salario sps\n",
    "        on vsm.nome_pais = sps.pais\n",
    "    )\n",
    "    select pais, count(*) as total\n",
    "    from maior_cinco_salarios_minimos\n",
    "    where salario > cinco_salarios_minimos\n",
    "    group by pais\n",
    "    order by total desc;\n",
    "\"\"\").toPandas().head()"
   ]
  }
 ],
 "metadata": {
  "application/vnd.databricks.v1+notebook": {
   "dashboards": [],
   "language": "python",
   "notebookMetadata": {
    "mostRecentlyExecutedCommandWithImplicitDF": {
     "commandId": 2350205126574382,
     "dataframes": [
      "_sqldf"
     ]
    },
    "pythonIndentUnit": 4
   },
   "notebookName": "Challenge AME",
   "widgets": {}
  },
  "kernelspec": {
   "display_name": "pipe_eng",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
